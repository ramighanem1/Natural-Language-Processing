# GPT-3

    GPT-3 (Generative Pre-trained Transformer 3) is a large-scale artificial intelligence language model developed by OpenAI with 175 B Parameters, 96 attention layers and 3.2 M batch size.

the steps taken by GPT-3 to answer questions :

- Tokenization: The input text is broken down into smaller pieces called tokens. These tokens are usually words or sub-words.

- Embedding: Each token is then assigned a numerical vector representation based on its meaning and context. This is called embedding.

- Encoding: The embedded tokens are fed into the transformer network, which consists of multiple layers of neural networks. The transformer     network is pre-trained on a large corpus of text to learn the patterns and relationships between the words in a sentence.

- Prediction: The model then predicts the most likely next word or sequence of words based on the context provided by the input text.

- Output: Finally, the model generates a response or output text based on the predicted words.



# DALL-E-2

    DALL-E-2 is an artificial intelligence program developed by OpenAI that can generate novel images from textual descriptions. It uses a deep learning approach called generative adversarial networks (GANs) to create these images.


steps taken by DALL-E-2 to create an image:

- Text Encoding: The textual description is first encoded into a numerical vector representation using a technique called word embedding. The encoding captures the semantic meaning of the description and allows the model to understand the underlying structure of the text.

- Image Generation: The encoded textual description is then fed into the generative adversarial network (GAN) consisting of two deep neural networks, a generator, and a discriminator. The generator takes the encoded text as input and generates a low-resolution image.

- Refinement: The low-resolution image generated by the generator is then passed through a series of refinement stages to increase its resolution and make it more realistic. These refinement stages typically consist of convolutional neural networks (CNNs) that apply a series of filters to the image to add details and remove noise.

- Discrimination: The refined image is then evaluated by the discriminator, which is trained to distinguish between real images and those generated by the generator. The discriminator provides feedback to the generator on how to improve the generated image and make it more realistic.

- Output: The process of refinement and discrimination is repeated several times until the generator produces a high-quality image that satisfies the discriminator's criteria. The final output image is then generated based on the textual description provided as input.


